{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dcf4c31",
   "metadata": {},
   "source": [
    "# 🚀 Jupyter Lab Data Science Project Setup\n",
    "\n",
    "Welcome to your professional Jupyter Lab data science environment using Docker Compose!\n",
    "\n",
    "This notebook demonstrates setting up and using our containerized data science environment with the `jupyter/datascience-notebook` Docker image and Docker Compose v2.39.1.\n",
    "\n",
    "## 📋 Table of Contents\n",
    "1. [Project Structure Setup](#project-structure)\n",
    "2. [Docker Compose Configuration](#docker-compose-config)\n",
    "3. [Environment Variables Configuration](#env-config)\n",
    "4. [Volume Mounts and Networking](#volumes-networking)\n",
    "5. [Build and Launch Environment](#build-launch)\n",
    "6. [Verify Installation and Access](#verify-installation)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f2790",
   "metadata": {},
   "source": [
    "## 1. Project Structure Setup {#project-structure}\n",
    "\n",
    "Our project follows a professional data science directory structure that promotes organization and reproducibility:\n",
    "\n",
    "```\n",
    "JupyterLab/\n",
    "├── docker-compose.yml          # Main Docker Compose configuration\n",
    "├── .env.example               # Environment variables template\n",
    "├── .env                      # Your environment variables (create from .env.example)\n",
    "├── .gitignore               # Git ignore rules\n",
    "├── README.md                # Project documentation\n",
    "├── requirements.txt         # Additional Python packages\n",
    "├── notebooks/               # Jupyter notebooks (organized by purpose)\n",
    "│   ├── exploratory/        # Data exploration notebooks\n",
    "│   ├── analysis/           # Analysis notebooks  \n",
    "│   ├── modeling/           # Machine learning models\n",
    "│   └── reports/            # Report notebooks\n",
    "├── data/                   # Dataset storage\n",
    "│   ├── raw/               # Raw, unprocessed data\n",
    "│   ├── processed/         # Cleaned and processed data\n",
    "│   └── external/          # External datasets\n",
    "├── scripts/               # Python modules and utilities\n",
    "│   ├── __init__.py       # Make it a Python package\n",
    "│   ├── utils.py          # Utility functions\n",
    "│   ├── data_processing.py # Data processing functions\n",
    "│   └── visualization.py  # Visualization helpers\n",
    "├── outputs/               # Generated outputs\n",
    "│   ├── figures/          # Charts and plots\n",
    "│   ├── models/           # Trained models\n",
    "│   └── reports/          # Generated reports\n",
    "└── database/             # Database initialization scripts\n",
    "    └── init/             # PostgreSQL init scripts\n",
    "```\n",
    "\n",
    "### Key Benefits:\n",
    "- **Separation of concerns**: Clear distinction between raw data, processed data, code, and outputs\n",
    "- **Reproducibility**: Consistent structure makes projects easier to understand and reproduce\n",
    "- **Collaboration**: Team members can quickly navigate and contribute to the project\n",
    "- **Version control**: Organized structure works well with Git workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eb27da",
   "metadata": {},
   "source": [
    "## 2. Docker Compose Configuration {#docker-compose-config}\n",
    "\n",
    "Our `docker-compose.yml` file uses **Compose version 2.39.1** syntax and the `jupyter/datascience-notebook:latest` image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2dde30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine our Docker Compose configuration\n",
    "with open('../docker-compose.yml', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "print(\"=== Docker Compose Configuration ===\")\n",
    "print(content[:1500] + \"...\" if len(content) > 1500 else content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283dc554",
   "metadata": {},
   "source": [
    "### Key Docker Compose Features:\n",
    "\n",
    "- **jupyter/datascience-notebook:latest**: Pre-installed with pandas, numpy, matplotlib, seaborn, scikit-learn, and more\n",
    "- **Volume Mounts**: Persistent storage for notebooks, data, scripts, and outputs\n",
    "- **Optional Services**: PostgreSQL database and Redis cache (use profiles to enable)\n",
    "- **Custom Network**: Isolated network for service communication\n",
    "- **Environment Variables**: Flexible configuration through `.env` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d0b6d",
   "metadata": {},
   "source": [
    "## 3. Environment Variables Configuration {#env-config}\n",
    "\n",
    "Environment variables provide secure and flexible configuration management. Let's examine the `.env.example` template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine environment variables template\n",
    "with open('../.env.example', 'r') as f:\n",
    "    env_content = f.read()\n",
    "\n",
    "print(\"=== Environment Variables Template ===\")\n",
    "print(env_content)\n",
    "\n",
    "print(\"\\n=== Setup Instructions ===\")\n",
    "print(\"1. Copy .env.example to .env: cp .env.example .env\")\n",
    "print(\"2. Edit .env file with your preferred settings\")\n",
    "print(\"3. Never commit .env file to version control (it's in .gitignore)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c134a71",
   "metadata": {},
   "source": [
    "## 4. Volume Mounts and Networking {#volumes-networking}\n",
    "\n",
    "Our Docker Compose setup includes sophisticated volume mounting and networking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba31b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"=== Volume Mounts Configuration ===\")\n",
    "print(\"Host Directory -> Container Directory\")\n",
    "print(\"./notebooks -> /home/jovyan/work/notebooks\")\n",
    "print(\"./data -> /home/jovyan/work/data\") \n",
    "print(\"./scripts -> /home/jovyan/work/scripts\")\n",
    "print(\"./outputs -> /home/jovyan/work/outputs\")\n",
    "\n",
    "print(\"\\n=== Current Directory Structure ===\")\n",
    "for root, dirs, files in os.walk('../'):\n",
    "    level = root.replace('../', '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:3]:  # Show first 3 files only\n",
    "        print(f'{subindent}{file}')\n",
    "    if len(files) > 3:\n",
    "        print(f'{subindent}... and {len(files) - 3} more files')\n",
    "\n",
    "print(\"\\n=== Network Configuration ===\")\n",
    "print(\"- Custom bridge network: jupyter-network\")\n",
    "print(\"- Isolated container communication\")\n",
    "print(\"- Host access via port 8888\")\n",
    "print(\"- Optional database services on custom network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257fda0e",
   "metadata": {},
   "source": [
    "## 5. Build and Launch Environment {#build-launch}\n",
    "\n",
    "Here are the essential Docker Compose commands for managing your environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efcbf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Essential Docker Compose Commands ===\")\n",
    "print()\n",
    "\n",
    "commands = {\n",
    "    \"Start Jupyter Lab only\": \"docker compose up -d\",\n",
    "    \"Start with PostgreSQL\": \"docker compose --profile database up -d\", \n",
    "    \"Start with all services\": \"docker compose --profile database --profile cache up -d\",\n",
    "    \"View logs\": \"docker compose logs jupyter\",\n",
    "    \"Stop services\": \"docker compose down\",\n",
    "    \"Restart Jupyter\": \"docker compose restart jupyter\",\n",
    "    \"Access container shell\": \"docker compose exec jupyter bash\",\n",
    "    \"Install packages\": \"docker compose exec jupyter pip install package-name\",\n",
    "    \"Update services\": \"docker compose pull && docker compose up -d\"\n",
    "}\n",
    "\n",
    "for description, command in commands.items():\n",
    "    print(f\"📌 {description}:\")\n",
    "    print(f\"   {command}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== Troubleshooting Tips ===\")\n",
    "print(\"• Port conflicts: Change JUPYTER_PORT in .env file\")\n",
    "print(\"• Permission issues: Run 'docker compose exec jupyter chown -R jovyan:users /home/jovyan/work'\") \n",
    "print(\"• Package issues: Use conda for complex packages: 'docker compose exec jupyter conda install package-name'\")\n",
    "print(\"• Reset environment: 'docker compose down && docker compose up -d'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff36819",
   "metadata": {},
   "source": [
    "## 6. Verify Installation and Access {#verify-installation}\n",
    "\n",
    "Let's verify that our Jupyter environment is working correctly by testing key components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Test System Information\n",
    "import sys\n",
    "import platform\n",
    "print(\"=== System Information ===\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Architecture: {platform.architecture()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Test Essential Data Science Libraries\n",
    "print(\"=== Testing Essential Libraries ===\")\n",
    "\n",
    "# Test imports\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import plotly.express as px\n",
    "    import sklearn\n",
    "    print(\"✅ All essential libraries imported successfully!\")\n",
    "    print(f\"   • pandas: {pd.__version__}\")\n",
    "    print(f\"   • numpy: {np.__version__}\")\n",
    "    print(f\"   • matplotlib: {plt.matplotlib.__version__}\")\n",
    "    print(f\"   • seaborn: {sns.__version__}\")\n",
    "    print(f\"   • scikit-learn: {sklearn.__version__}\")\n",
    "    print(\"   • plotly: Available\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e72c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Test Custom Utilities\n",
    "print(\"=== Testing Custom Utilities ===\")\n",
    "try:\n",
    "    # Add the scripts directory to the Python path\n",
    "    sys.path.append('/home/jovyan/work/scripts')\n",
    "    \n",
    "    from scripts.utils import get_project_root, setup_logging\n",
    "    from scripts.data_processing import clean_column_names\n",
    "    from scripts.visualization import setup_matplotlib_style\n",
    "    \n",
    "    print(\"✅ Custom utilities imported successfully!\")\n",
    "    print(f\"   • Project root: {get_project_root()}\")\n",
    "    print(\"   • Data processing utilities: Available\")\n",
    "    print(\"   • Visualization utilities: Available\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Custom utilities error: {e}\")\n",
    "    print(\"   This is normal if running outside the Docker container\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ba3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create and Test Sample Data\n",
    "print(\"=== Creating Sample Dataset ===\")\n",
    "\n",
    "# Create sample data\n",
    "sample_data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'age': [25, 30, 35, 28, 32],\n",
    "    'city': ['New York', 'London', 'Tokyo', 'Paris', 'Sydney'],\n",
    "    'salary': [70000, 80000, 90000, 75000, 85000],\n",
    "    'department': ['Engineering', 'Marketing', 'Engineering', 'Sales', 'Marketing']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sample_data)\n",
    "print(\"✅ Sample DataFrame created:\")\n",
    "print(df)\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "print(f\"Data types:\\n{df.dtypes}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ac8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Test Matplotlib Visualization\n",
    "print(\"=== Testing Matplotlib Visualization ===\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar plot\n",
    "ax1.bar(df['name'], df['age'])\n",
    "ax1.set_title('Age by Person')\n",
    "ax1.set_xlabel('Name')\n",
    "ax1.set_ylabel('Age')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Scatter plot\n",
    "departments = df['department'].unique()\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(departments)))\n",
    "for i, dept in enumerate(departments):\n",
    "    dept_data = df[df['department'] == dept]\n",
    "    ax2.scatter(dept_data['age'], dept_data['salary'], \n",
    "               label=dept, color=colors[i], s=100, alpha=0.7)\n",
    "\n",
    "ax2.set_title('Salary vs Age by Department')\n",
    "ax2.set_xlabel('Age')\n",
    "ax2.set_ylabel('Salary')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Matplotlib visualization test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Test Interactive Plotly Visualization\n",
    "print(\"=== Testing Plotly Interactive Visualization ===\")\n",
    "\n",
    "# Create interactive scatter plot\n",
    "fig = px.scatter(df, x='age', y='salary', color='department', size='age',\n",
    "                 hover_data=['name'], title='Interactive Salary vs Age by Department')\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=500,\n",
    "    showlegend=True,\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"✅ Plotly interactive visualization test completed!\")\n",
    "print(\"\\n=== Next Steps ===\")\n",
    "print(\"🎉 Your Jupyter Lab environment is ready!\")\n",
    "print(\"• Access Jupyter Lab at: http://localhost:8888\")\n",
    "print(\"• Default token: datascience-token (change in .env)\")\n",
    "print(\"• Explore the notebooks/ directory for more examples\")\n",
    "print(\"• Check out the scripts/ directory for utility functions\")\n",
    "print(\"• Use the data/ directory for your datasets\")\n",
    "print(\"• Save outputs to the outputs/ directory\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
